{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# YOLOv8 Pipeline on MinneApple Dataset\n",
        "\n",
        "This notebook demonstrates how to:\n",
        "1. Install YOLOv8 and PyTorch\n",
        "2. Mount Google Drive and copy YOLOv8 project\n",
        "3. Data Acquisition and Preprocessing\n",
        "4. Convert COCO ground-truth annotations to YOLO format\n",
        "5. Train and validate the YOLOv8 model\n",
        "6. Perform inference on new images"
      ],
      "metadata": {
        "id": "RkcvKIbfu5-v"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. **Install Dependencies**"
      ],
      "metadata": {
        "id": "u0lSu_i2vErd"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pNDeBRHPutxh"
      },
      "outputs": [],
      "source": [
        "!pip install ultralytics\n",
        "!pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. **Mount Google Drive**\n"
      ],
      "metadata": {
        "id": "cydDaX1MvIj7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s-EbWAGDvJa9",
        "outputId": "37f08728-ec21-4bc5-9139-9603b632cdc3"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. **Extraction of Minne Apple Dataset**\n",
        "[MinneApple Dataset Link](https://rsn.umn.edu/projects/orchard-monitoring/minneapple)\n",
        "\n",
        "Classify the folders in the Yolo format for training and validation, using images and labels respectively"
      ],
      "metadata": {
        "id": "HSxKpVpQ3yAZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip /content/drive/MyDrive/archive.zip -d /content/drive/MyDrive/archive\n"
      ],
      "metadata": {
        "id": "PCYvvyqi3uMq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4. **Code for YOLO Labels Generation from masks**\n"
      ],
      "metadata": {
        "id": "34Bh5Idz5WQP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import cv2\n",
        "from glob import glob\n",
        "\n",
        "masks_path = \"/content/drive/MyDrive/MinneApple/MinneApple/detection/train/masks\"\n",
        "image_path = \"/content/drive/MyDrive/MinneApple/MinneApple/detection/train/images\"\n",
        "labels_path = \"/content/drive/MyDrive/MinneApple/MinneApple/detection/train/labels\"\n",
        "\n",
        "mask_files = glob(os.path.join(masks_path, \"*.png\"))\n",
        "print(f\"Number of mask files found: {len(mask_files)}\")\n",
        "print(\"Mask files:\", mask_files[:10])  # Print the first 10 mask file names for verifying\n",
        "os.makedirs(labels_path, exist_ok=True)"
      ],
      "metadata": {
        "id": "l0FPiC705oMw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#To find all the .png files in masks folder"
      ],
      "metadata": {
        "id": "5so8v3Tu5_sI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "for each_masks_path in mask_files:\n",
        "    mask = cv2.imread(each_masks_path, cv2.IMREAD_GRAYSCALE) #0-255 - cv2.imread() defaultly reads image in BGR\n",
        "    if mask is None:\n",
        "      print(f\"Failed path: {each_masks_path}\")\n",
        "      continue\n",
        "    #RETR_EXTERNAL to ignore nested contours\n",
        "    #CHAIN_APPROX_SIMPLE to store essential contour points\n",
        "    boundaries, _ = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
        "    print(f\"{each_masks_path} - Number of contours found: {len(boundaries)}\")\n",
        "\n",
        "    annotations_yolo = []\n",
        "    for boundary in boundaries:\n",
        "      x, y, w, h = cv2.boundingRect(boundary)   #x, y Rectangle top left   #w- width, h - height\n",
        "\n",
        "      height, width = mask.shape  #Dimensions\n",
        "      horizonal_center = (x + w / 2)/width   #Centers of rectangle - fraction of img size\n",
        "      vertical_center =  (y + h / 2)/height\n",
        "      width_fraction = w/width #Normalization of bounding box # \\cite \"You Only Look Once: Unified, Real-Time Object Detection.\"\n",
        "      height_fraction = h/height\n",
        "\n",
        "      annotations_yolo.append(f\"0 {horizonal_center} {vertical_center} {width_fraction} {height_fraction}\") # 0 = class ID for Apple\n",
        "\n",
        "\n",
        "\n",
        "    labels_file_name = os.path.basename(each_masks_path).replace(\".png\",\".txt\")  # mask to .txt\n",
        "    labels_file_path = os.path.join(labels_path, labels_file_name)\n",
        "\n",
        "    with open(labels_file_path,\"w\") as file:   #Saving annotations to labels_file_path\n",
        "      file.write(\"\\n\".join(annotations_yolo)) #New line each # for annotation in annotations_yolo:\n",
        "\n",
        "print(f\"Labels Saved: {labels_file_name}\")\n",
        "print(f\"Mask label file name: {labels_file_path}\")"
      ],
      "metadata": {
        "id": "RHpP-bN1584I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Checking the count of images and labels in the dataset for trainging"
      ],
      "metadata": {
        "id": "j4kcvK0x6RUA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_images_count = len([file for file in os.listdir(image_path) if file.endswith(\".png\")])\n",
        "train_labels_count = len([file for file in os.listdir(labels_path) if file.endswith(\".txt\")])\n",
        "\n",
        "# Print counts\n",
        "print(f\"Number of train images: {train_images_count}\")\n",
        "print(f\"Number of train labels: {train_labels_count}\")"
      ],
      "metadata": {
        "id": "8pTjBYEh6TSh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **5. Splitting images in train to 80% train, 20%val**"
      ],
      "metadata": {
        "id": "mYFQAdsH6feH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from glob import glob\n",
        "import shutil\n",
        "import random\n",
        "\n",
        "train_image_path = \"/content/drive/MyDrive/MinneApple/yolov8/final_data/train/images\"\n",
        "train_labels_path = \"/content/drive/MyDrive/MinneApple/yolov8/final_data/train/labels\"\n",
        "val_images_path = \"/content/drive/MyDrive/MinneApple/yolov8/final_data/val/images\"\n",
        "val_labels_path = \"/content/drive/MyDrive/MinneApple/yolov8/final_data/val/labels\"\n",
        "\n",
        "os.makedirs(val_images_path, exist_ok=True)\n",
        "os.makedirs(val_labels_path, exist_ok=True)\n",
        "\n",
        "image_files = glob(os.path.join(train_image_path, \"*.jpg\"))\n",
        "random.shuffle(image_files)\n",
        "\n",
        "index_split_division = int(0.9 * len(image_files))\n",
        "training_files = image_files[:index_split_division]\n",
        "validation_files = image_files[index_split_division:]\n",
        "\n",
        "for image_val in validation_files:\n",
        "  shutil.move(image_val, os.path.join(val_images_path, os.path.basename(image_val))) #To move images\n",
        "\n",
        "  label_folder = os.path.join(train_labels_path, os.path.basename(image_val).replace(\".jpg\",\".txt\"))\n",
        "  if os.path.exists(label_folder):\n",
        "    shutil.move(label_folder, os.path.join(val_labels_path, os.path.basename(label_folder)))\n",
        "\n",
        "print(f\"{len(validation_files)} moved to val\")\n"
      ],
      "metadata": {
        "id": "Huf2z6lS6lqA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# The Datsets used include:\n",
        "1. **MinneApple Dataset**\n",
        "2. **Kaggle Dataset**\n",
        "3. **Custom annotated dataset using Roboflow**"
      ],
      "metadata": {
        "id": "N8KjN9Lf7dS5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Code to Count files in each folder**\n",
        "\n",
        "\n",
        "\n",
        "In this training the total count was:\n",
        "\n",
        "1.   Number of train images: 2198\n",
        "2.   Number of train labels: 2184\n",
        "3.   Number of validation images: 318\n",
        "4.   Number of validation labels: 317"
      ],
      "metadata": {
        "id": "TQEEfayH6wdR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_images_count = len([file for file in os.listdir(train_image_path) if file.endswith((\".jpg\",\".png\"))])\n",
        "train_labels_count = len([file for file in os.listdir(train_labels_path) if file.endswith(\".txt\")])\n",
        "val_images_count = len([file for file in os.listdir(val_images_path) if file.endswith((\".jpg\",\".png\"))])\n",
        "val_labels_count = len([file for file in os.listdir(val_labels_path) if file.endswith(\".txt\")])\n",
        "\n",
        "# Print counts\n",
        "print(f\"train images: {train_images_count}\")\n",
        "print(f\"train labels: {train_labels_count}\")\n",
        "print(f\"validation images: {val_images_count}\")\n",
        "print(f\"validation labels: {val_labels_count}\")"
      ],
      "metadata": {
        "id": "cTYEDfhj6uO4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Code to copy img and txt from Minne to final data\n",
        " Mix of MINNE+KAGGLE because both contain large number of images"
      ],
      "metadata": {
        "id": "J9XzCVQ77w2l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import shutil\n",
        "\n",
        "# Define source and destination folders\n",
        "folders = [\n",
        "    {\n",
        "        \"images\": \"/content/drive/MyDrive/MinneApple/yolov8/dataset/images/train\",\n",
        "        \"labels\": \"/content/drive/MyDrive/MinneApple/yolov8/dataset/labels/train\"\n",
        "     },\n",
        "    {\n",
        "        \"images\": \"/content/drive/MyDrive/MinneApple/yolov8/dataset/images/val\",\n",
        "        \"labels\": \"/content/drive/MyDrive/MinneApple/yolov8/dataset/labels/val\"\n",
        "     }\n",
        "]\n",
        "\n",
        "destination_folders = [\n",
        "    {\n",
        "        \"images\": \"/content/drive/MyDrive/MinneApple/yolov8/final_data/train/images\",\n",
        "        \"labels\": \"/content/drive/MyDrive/MinneApple/yolov8/final_data/train/labels\"\n",
        "        },\n",
        "    {\n",
        "        \"images\": \"/content/drive/MyDrive/MinneApple/yolov8/final_data/val/images\",\n",
        "        \"labels\": \"/content/drive/MyDrive/MinneApple/yolov8/final_data/val/labels\"\n",
        "    }\n",
        "]\n",
        "# Ensure destination folders exist\n",
        "for dest in destination_folders:\n",
        "    os.makedirs(dest[\"images\"], exist_ok=True)\n",
        "    os.makedirs(dest[\"labels\"], exist_ok=True)\n",
        "\n",
        "def copy_files(src_folder, dest_folder, file_extension):\n",
        "    \"\"\"\n",
        "    Copies files with a specific extension from the source to the destination folder.\n",
        "    \"\"\"\n",
        "    for root, _, files in os.walk(src_folder):\n",
        "        for file in files:\n",
        "            if file.endswith(file_extension):\n",
        "                src_file = os.path.join(root, file)\n",
        "                dest_file = os.path.join(dest_folder, file)\n",
        "                 # Print source and destination file paths for confirmation\n",
        "                print(f\"Copying: {src_file} -> {dest_file}\")\n",
        "                shutil.copy2(src_file, dest_file)\n",
        "# Copy images and labels\n",
        "for i in range(len(folders)):\n",
        "    src = folders[i]\n",
        "    dest = destination_folders[i]\n",
        "    # copy_files(src[\"images\"], dest[\"images\"], \".jpg\")\n",
        "    copy_files(src[\"images\"], dest[\"images\"], \".png\")\n",
        "    copy_files(src[\"labels\"], dest[\"labels\"], \".txt\")\n",
        "\n",
        "print(\"Files copied successfully!\")\n"
      ],
      "metadata": {
        "id": "OJRUNOR67_nw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Code to check and verify missing label image pair**"
      ],
      "metadata": {
        "id": "cNl7Gpxx8KFU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "# Paths\n",
        "val_images_dir = \"/content/drive/MyDrive/MinneApple/MinneApple/detection/val/images\"\n",
        "val_labels_dir = \"/content/drive/MyDrive/MinneApple/MinneApple/detection/val/labels\"\n",
        "\n",
        "# Get list of image and label files\n",
        "val_images = {os.path.splitext(f)[0] for f in os.listdir(val_images_dir) if f.endswith(\".png\")}\n",
        "val_labels = {os.path.splitext(f)[0] for f in os.listdir(val_labels_dir) if f.endswith(\".txt\")}\n",
        "\n",
        "# Find unmatched files\n",
        "missing_images = val_labels - val_images  # Labels without images\n",
        "missing_labels = val_images - val_labels  # Images without labels\n",
        "\n",
        "print(f\"Labels without images: {missing_images}\")\n",
        "print(f\"Images without labels: {missing_labels}\")"
      ],
      "metadata": {
        "id": "p-nStOS_8QFB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Training**"
      ],
      "metadata": {
        "id": "-IhNcf5O8XYz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. **Check CUDA & GPU**\n"
      ],
      "metadata": {
        "id": "HnVKZ2Q7vVOV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "print(\"CUDA Available:\", torch.cuda.is_available())\n",
        "print(\"Device Name:\", torch.cuda.get_device_name(0) if torch.cuda.is_available() else \"CPU\")\n",
        "\n",
        "!nvidia-smi\n"
      ],
      "metadata": {
        "id": "-BMDvqFVvV99"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4. **Train YOLOv8 Model**\n",
        "\n",
        "Below, train using the `ultralytics` package.\n",
        "Adjust `data`, `epochs`, `batch`, `imgsz`, and `device` as needed.\n"
      ],
      "metadata": {
        "id": "lng3jGU-vedl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from ultralytics import YOLO\n",
        "\n",
        "# Load a pretrained YOLOv8 model (e.g., yolov8n, yolov8s, yolov8m, yolov8l, yolov8x)\n",
        "model = YOLO('yolov8s.pt')\n",
        "\n",
        "# Train the model\n",
        "model.train(\n",
        "    data=\"/content/drive/MyDrive/MinneApple/yolov8/final_data/final.yaml\",  # Path to dataset config\n",
        "    epochs=50,\n",
        "    batch=16,\n",
        "    imgsz=640,\n",
        "    project=\"/content/drive/MyDrive/MinneApple/yolov8/final_data\",  # Where results are saved\n",
        "    name=\"combined_model\",\n",
        "    device=0  # 0 for GPU, or 'cpu' for CPU\n",
        ")"
      ],
      "metadata": {
        "id": "LNvKoWmFvfI2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5. **Check Missing Labels or Images**\n",
        "\n",
        "This script checks if there are any images without corresponding annotated label files or vice versa.\n"
      ],
      "metadata": {
        "id": "bXe-UwcYv-D-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "val_images_path = '/content/drive/MyDrive/MinneApple/yolov8/data/images/val'\n",
        "val_labels_path = '/content/drive/MyDrive/MinneApple/yolov8/data/labels/val'\n",
        "\n",
        "image_files = [os.path.splitext(f)[0] for f in os.listdir(val_images_path) if f.endswith(('.png', '.jpg'))]\n",
        "label_files = [os.path.splitext(f)[0] for f in os.listdir(val_labels_path) if f.endswith('.txt')]\n",
        "\n",
        "missing_labels = [img for img in image_files if img not in label_files]\n",
        "missing_images = [label for label in label_files if label not in image_files]\n",
        "\n",
        "print(f\"Images without labels: {missing_labels}\")\n",
        "print(f\"Labels without images: {missing_images}\")\n"
      ],
      "metadata": {
        "id": "THGGa1alwII9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 6. **Alternative YOLOv8 Training (CLI Command)**\n",
        "\n",
        "Training via the `yolo` CLI. Example 1-epoch training just as a demo.\n"
      ],
      "metadata": {
        "id": "FTa-Ll4TwN91"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!yolo task=detect mode=train model=yolov8n.pt \\\n",
        "    data=/content/drive/MyDrive/MinneApple/yolov8/final_data/final.yaml \\\n",
        "    epochs=1 batch=16 imgsz=640 \\\n",
        "    project=/content/drive/MyDrive \\\n",
        "    name=result_expt\n"
      ],
      "metadata": {
        "id": "7GczgrcUwVDu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 9. **Inference on Trained YOLOv8s Model**\n",
        "\n",
        "Below inference is run on YOLOv8 model trained using a combination of 3 datasets of 3000 images\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "YJw-gEGNwW-l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        " @misc{hani2019minneapple,\n",
        "    title={MinneApple: A Benchmark Dataset for Apple Detection and Segmentation},\n",
        "    author={Nicolai Häni and Pravakar Roy and Volkan Isler}\n",
        "    year={2019},\n",
        "    eprint={1909.06441},\n",
        "    archivePrefix={arXiv},\n",
        "    primaryClass={cs.CV}\n",
        "}"
      ],
      "metadata": {
        "id": "lQm511gIzTyO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from ultralytics import YOLO\n",
        "\n",
        "# Load the trained model (combined)\n",
        "model_combined = YOLO(\"/content/drive/MyDrive/MinneApple/yolov8/final_data/combined_model/weights/best.pt\")\n",
        "\n",
        "# Run inference on a list of images\n",
        "results_combined = model_combined([\"/content/drive/MyDrive/yolov8/dataset1_back_181.png\"])\n",
        "\n",
        "# Display & save results\n",
        "for result in results_combined:\n",
        "    result.show()\n",
        "    result.save(\"result_combined.jpg\")"
      ],
      "metadata": {
        "id": "_Pg_yYNxwggs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 10. **Inference with Minne-only Model**\n",
        "\n",
        "Here, a model trained only on MinneApple dataset is loaded for comparison\n"
      ],
      "metadata": {
        "id": "jr1TFxhDyd39"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_minne = YOLO(\"/content/drive/MyDrive/yolov8/runs/train/minneapple2/best (2).pt\")\n",
        "\n",
        "results_minne = model_minne([\"/content/drive/MyDrive/yolov8/dataset1_back_181.png\"])\n",
        "for result in results_minne:\n",
        "    result.show()\n",
        "    result.save(\"result_minne.jpg\")\n"
      ],
      "metadata": {
        "id": "zGSEnn21yWpw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 12. **Convert COCO Ground Truth to YOLO Format**\n",
        "\n",
        "This section converts `ground_truth.json` (COCO format) into YOLO label files.\n"
      ],
      "metadata": {
        "id": "VCR73Z7-0jIf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import os\n",
        "\n",
        "coco_json_path = \"/content/drive/MyDrive/yolov8/ground_truth.json\"\n",
        "output_dir = \"output_labels\"\n",
        "os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "with open(coco_json_path, 'r') as file:\n",
        "    coco_data = json.load(file)\n",
        "\n",
        "image_id_to_filename = {image['id']: image['filename'] for image in coco_data['images']}\n",
        "image_id_to_size = {image['id']: (image['width'], image['height']) for image in coco_data['images']}\n",
        "\n",
        "for annotation in coco_data['annotations']:\n",
        "    image_id = annotation['image_id']\n",
        "    bbox = annotation['bbox']\n",
        "    category_id = annotation['category_id']\n",
        "    width, height = image_id_to_size[image_id]\n",
        "\n",
        "    x_center = (bbox[0] + bbox[2] / 2) / width\n",
        "    y_center = (bbox[1] + bbox[3] / 2) / height\n",
        "    bbox_width = bbox[2] / width\n",
        "    bbox_height = bbox[3] / height\n",
        "\n",
        "    # YOLO label line\n",
        "    yolo_line = f\"{category_id} {x_center:.6f} {y_center:.6f} {bbox_width:.6f} {bbox_height:.6f}\\n\"\n",
        "\n",
        "    # Change extension to .txt\n",
        "    filename = image_id_to_filename[image_id].replace('.png', '.txt')\n",
        "    label_path = os.path.join(output_dir, filename)\n",
        "\n",
        "    # Append (in case multiple annotations exist for one image)\n",
        "    with open(label_path, 'a') as label_file:\n",
        "        label_file.write(yolo_line)\n",
        "\n",
        "print(f\"Labels have been saved to {output_dir}\")\n"
      ],
      "metadata": {
        "id": "aRPrO3_50mEl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Results**\n",
        "mAP@50, PR curve, F1 curve, Normalization matrix generated during this processs can be used to evaluate the perfrmance of the model. Further adding more annotated images and increasing the number of training epochs will help imrpove the model metrics"
      ],
      "metadata": {
        "id": "CNSUMcFo_GFQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Conclusion**\n",
        "\n",
        "**Installing Dependencies** – Set up YOLOv8, PyTorch, and Google Colab environment.\n",
        "\n",
        "**Mounting Google Drive** – Load dataset and project files from Drive.\n",
        "\n",
        "**Data Acquisition & Preprocessing** – Extract MinneApple dataset and generate YOLO labels from segmentation masks.\n",
        "\n",
        "**Dataset Splitting & Organization**– Classified data into train and validation sets (80-20 split).\n",
        "\n",
        "**Dataset Combination** – Merged MinneApple, Kaggle, and custom datasets for improved model robustness.\n",
        "\n",
        "**Data Verification & Quality Check** – Ensured each image has a corresponding label file.\n",
        "\n",
        "**Training YOLOv8 Model** – Used 50 epochs, batch size 16, and 640×640 images for detection.\n",
        "\n",
        "**Validating Training Results** – Analyzed loss curves and mAP (mean Average Precision).\n",
        "\n",
        "**Inference on Trained YOLOv8 Model** – Compared model performance on MinneApple-only vs. combined dataset.\n",
        "\n",
        "**Ground Truth Annotations Conversion** – Converted COCO JSON annotations to YOLO format.\n",
        "\n",
        "**Next Steps**:\n",
        "1. Tweak hyperparameters (epochs, batch size, etc.) for better accuracy.\n",
        "2. Use more advanced YOLOv8 variants (`yolov8m`, `yolov8l`) if GPU allows.\n",
        "3. Share or push this notebook to GitHub to showcase work.\n"
      ],
      "metadata": {
        "id": "b8l9x5ZU0pgV"
      }
    }
  ]
}